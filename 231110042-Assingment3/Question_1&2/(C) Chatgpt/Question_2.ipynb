{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "856763c0-a8a5-4de4-95a7-8a8e62fd8415",
   "metadata": {},
   "source": [
    "# ChatGPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5e441b3b-af4e-428b-982c-2bae34837136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aa382064-903c-4663-a391-92e7208bfe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bleu_score(ground_truth , output):\n",
    "    b_score = 0\n",
    "    b_score = corpus_bleu([[ref] for ref in ground_truth], output)\n",
    "    return b_score\n",
    "   \n",
    "\n",
    "\n",
    "def rouge_score(ground_truth , output):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(ground_truth,output,avg=True)\n",
    "    return scores\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eef739-d726-458c-aad6-48a83b280962",
   "metadata": {},
   "source": [
    "### Hindi to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e47339e9-5358-4b0c-9721-6ce9343af498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file named \"example.txt\" in write mode ('w') with UTF-8 encoding\n",
    "with open('hin_to_eng_input.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    input = f.readlines()\n",
    "\n",
    "with open('hin_to_eng_output.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    output = f.readlines()\n",
    "\n",
    "with open('hi_to_eng_ground_truth.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    ground_truth = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3cad1b19-4ba4-4b04-82dc-6c9e703cdc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(input))\n",
    "# print(len(output))\n",
    "# print(len(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "45f24719-bc92-4dc0-95d2-a112b347c64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence BLEU Score: 0.7010350641310221\n"
     ]
    }
   ],
   "source": [
    "score = bleu_score(ground_truth , output)\n",
    "print(\"Sentence BLEU Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "44032227-753c-46f5-beca-3f04cf421fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge Score : \n",
      "rouge-1  :  {'r': 0.6540950310439474, 'p': 0.6424568561813144, 'f': 0.6443898180930964}\n",
      "rouge-2  :  {'r': 0.4065279020944656, 'p': 0.3978530591841267, 'f': 0.39929385766846354}\n",
      "rouge-l  :  {'r': 0.6163150052561815, 'p': 0.6068014478641414, 'f': 0.6079362112386781}\n"
     ]
    }
   ],
   "source": [
    "r_score = rouge_score(ground_truth , output)\n",
    "print(\"Rouge Score : \" )\n",
    "for i,j in r_score.items():\n",
    "    print(i,\" : \",j)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d949282-1667-4fd0-b2b2-eb74ab79c2ac",
   "metadata": {},
   "source": [
    "### English to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a549a117-ce4a-46f0-9631-97d1a9b943ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file named \"example.txt\" in write mode ('w') with UTF-8 encoding\n",
    "with open('eng_to_hin_input.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    input = f.readlines()\n",
    "\n",
    "with open('eng_to_hin_output.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    output = f.readlines()\n",
    "\n",
    "with open('eng_to_hin_ground_truth.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    ground_truth = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "64188921-ba5d-4231-a948-1f117a677d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(input))\n",
    "# # print(len(output))\n",
    "# print(len(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4af7be61-ed89-4d80-8808-f054cd4a5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence BLEU Score: 0.6087497144144103\n"
     ]
    }
   ],
   "source": [
    "score = bleu_score(ground_truth , output)\n",
    "print(\"Sentence BLEU Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9518e23f-d6e0-428b-9d2a-445fe98696e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge Score : \n",
      "rouge-1  :  {'r': 0.5457438548379725, 'p': 0.5225178257930578, 'f': 0.5318037220198154}\n",
      "rouge-2  :  {'r': 0.29074108795911857, 'p': 0.277388777491335, 'f': 0.2824066105138424}\n",
      "rouge-l  :  {'r': 0.5184900847518494, 'p': 0.49682734827951536, 'f': 0.5055046775268505}\n"
     ]
    }
   ],
   "source": [
    "r_score = rouge_score(ground_truth , output)\n",
    "print(\"Rouge Score : \" )\n",
    "for i,j in r_score.items():\n",
    "    print(i,\" : \",j)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e0748-6da5-4dac-8610-a31f19f6f041",
   "metadata": {},
   "source": [
    "### Hindi to Marathi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7f35ce67-6006-40ec-ae1c-147feae42339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file named \"example.txt\" in write mode ('w') with UTF-8 encoding\n",
    "with open('hin_to_mar_input.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    input = f.readlines()\n",
    "\n",
    "with open('hin_to_mar_output.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    output = f.readlines()\n",
    "\n",
    "with open('hin_to_mar_ground_truth.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    ground_truth = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "27f15e04-88bb-463f-8e54-436420ba08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((input[33]))\n",
    "# print((output[33]))\n",
    "# print((ground_truth[33]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4eb7a409-f9fc-4afb-9e2d-90ea69d7c7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence BLEU Score: 0.41635099662376235\n"
     ]
    }
   ],
   "source": [
    "score = bleu_score(ground_truth , output)\n",
    "print(\"Sentence BLEU Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d3ebfb37-d287-4382-a895-1169526b9505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge Score : \n",
      "rouge-1  :  {'r': 0.2587855839438825, 'p': 0.2456614116018141, 'f': 0.2490714803991816}\n",
      "rouge-2  :  {'r': 0.0640758936289627, 'p': 0.06652414421278519, 'f': 0.0645416797374231}\n",
      "rouge-l  :  {'r': 0.24223161163031948, 'p': 0.2318914430083161, 'f': 0.23432072995617861}\n"
     ]
    }
   ],
   "source": [
    "r_score = rouge_score(ground_truth , output)\n",
    "print(\"Rouge Score : \" )\n",
    "for i,j in r_score.items():\n",
    "    print(i,\" : \",j)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b846bd5-b51c-49e8-9362-3009c40ebbf2",
   "metadata": {},
   "source": [
    "### Marathi to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d16b075d-4b45-4633-88dc-08487c9fb386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file named \"example.txt\" in write mode ('w') with UTF-8 encoding\n",
    "with open('mar_to_hin_input.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    input = f.readlines()\n",
    "\n",
    "with open('mar_to_hin_output.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    output = f.readlines()\n",
    "\n",
    "with open('mar_to_hin_ground_truth.txt', 'r', encoding='utf-8') as f:\n",
    "    # Write some text to the file\n",
    "    ground_truth = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4da72917-021c-461d-9ea8-2770161ac9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((input[33]))\n",
    "# print((output[33]))\n",
    "# print((ground_truth[33]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "480e1203-6dd8-4b0e-b971-048cb7ab537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence BLEU Score: 0.5250565219714854\n"
     ]
    }
   ],
   "source": [
    "score = bleu_score(ground_truth , output)\n",
    "print(\"Sentence BLEU Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "343cd8fa-1b16-4ede-a3c6-d14a4e26b391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge Score : \n",
      "rouge-1  :  {'r': 0.4320744258886153, 'p': 0.41752748746071533, 'f': 0.4201514222064645}\n",
      "rouge-2  :  {'r': 0.2065873548773089, 'p': 0.19672873613675873, 'f': 0.20042915620464058}\n",
      "rouge-l  :  {'r': 0.40107638772635673, 'p': 0.3895303078257649, 'f': 0.39100823004225743}\n"
     ]
    }
   ],
   "source": [
    "r_score = rouge_score(ground_truth , output)\n",
    "print(\"Rouge Score : \" )\n",
    "for i,j in r_score.items():\n",
    "    print(i,\" : \",j)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
